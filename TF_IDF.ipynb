{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re  # regular expression\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Recently, an exhibition ‘Building A New India’ was held in the capital. \n",
    "It was organized by the Ministry of Information and Broadcasting, Government of India.\n",
    "The exhibition was set up in the Triveni Kala Sangam. The chief exhibits were photographs, novels,\n",
    "some sculptures by Indian modern artists presenting Indian cultural inheritance. First of all, \n",
    "I visited the general section of the exhibition where different charts and photographs depicting \n",
    "India’s development in various fields were set. Most impressive photographs among these were those showing India’s \n",
    "nuclear development. The second section dealt with India’s magnificent historical background. I was fascinated by \n",
    "the pictures of Mohanjodaro excavation. Then I saw the most beautiful and colorful section of the exhibition i.e. \n",
    "the cultural section. It consisted of paintings, sculptures, photographs etc. The Rajasthani and Gujarati paintings\n",
    "were very colourful and attractive. This exhibition, inaugurated by the Prime Minister, lasted for a week. \n",
    "It proved to be of great educational value. It brushed up my knowledge about India as my motherland. \n",
    "It enhanced my respect for my great country, India. I would very much appreciate if the Indian government organized\n",
    "some more such exhibitions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Recently, an exhibition ‘Building A New India’ was held in the capital.', 'It was organized by the Ministry of Information and Broadcasting, Government of India.', 'The exhibition was set up in the Triveni Kala Sangam.', 'The chief exhibits were photographs, novels,\\nsome sculptures by Indian modern artists presenting Indian cultural inheritance.', 'First of all, \\nI visited the general section of the exhibition where different charts and photographs depicting \\nIndia’s development in various fields were set.', 'Most impressive photographs among these were those showing India’s \\nnuclear development.', 'The second section dealt with India’s magnificent historical background.', 'I was fascinated by \\nthe pictures of Mohanjodaro excavation.', 'Then I saw the most beautiful and colorful section of the exhibition i.e.', 'the cultural section.', 'It consisted of paintings, sculptures, photographs etc.', 'The Rajasthani and Gujarati paintings\\nwere very colourful and attractive.', 'This exhibition, inaugurated by the Prime Minister, lasted for a week.', 'It proved to be of great educational value.', 'It brushed up my knowledge about India as my motherland.', 'It enhanced my respect for my great country, India.', 'I would very much appreciate if the Indian government organized\\nsome more such exhibitions.']\n"
     ]
    }
   ],
   "source": [
    "# Initialize object \n",
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "# Sentence tokenizing\n",
    "sentence=nltk.sent_tokenize(paragraph)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=re.sub('[^a-zA-Z]',\" \",sentence[i])  # remove all charaters accpet alphabet\n",
    "    words=words.lower()\n",
    "    words=words.split()\n",
    "    \n",
    "    # Lemmatization\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    words=\" \".join(words)\n",
    "    corpus.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "\n",
    "cv=TfidfVectorizer()\n",
    "x=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.42043483, 0.        , ..., 0.        , 0.        ,\n",
       "        0.42043483]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
